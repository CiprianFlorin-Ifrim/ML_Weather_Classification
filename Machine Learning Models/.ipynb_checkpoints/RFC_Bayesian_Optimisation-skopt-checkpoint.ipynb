{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59c7e4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# automatic svm hyperparameter tuning using skopt \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "from IPython.core.display import display, HTML                                    \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ebe4d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Train Dataset is:  weather_data_2020_2021_4c_nosnow\n",
      "Your Test Dataset is:  weather_data_2019_4c_nosnow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleImputer(strategy='most_frequent')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset selection and loading\n",
    "train_set_name = \"weather_data_2020_2021_4c_nosnow\"\n",
    "train_dataset = pd.read_csv((\"./datasets/\" + train_set_name + \".csv\"),header=None)\n",
    "test_set_name = \"weather_data_2019_4c_nosnow\"\n",
    "test_dataset = pd.read_csv((\"./datasets/\" + test_set_name + \".csv\"),header=None) \n",
    "\n",
    "print(\"Your Train Dataset is: \", train_set_name)                                                                       #display dataset name to user\n",
    "print(\"Your Test Dataset is: \", test_set_name)                                                                       #display dataset name to user\n",
    "\n",
    "features_selected = 6\n",
    "#training features\n",
    "temperature_train = train_dataset.iloc[:, 4:5]\n",
    "feels_like_train = train_dataset.iloc[:, 7:8]\n",
    "dew_point_train = train_dataset.iloc[:, 8:9]\n",
    "humidity_train = train_dataset.iloc[:, 9:10]\n",
    "pressure_train = train_dataset.iloc[:, 19:20] \n",
    "uv_index_train = train_dataset.iloc[:, 24:25] \n",
    "\n",
    "#testing data\n",
    "temperature_test = test_dataset.iloc[:, 4:5]\n",
    "feels_like_test = test_dataset.iloc[:, 7:8]\n",
    "dew_point_test = test_dataset.iloc[:, 8:9]\n",
    "humidity_test = test_dataset.iloc[:, 9:10]\n",
    "pressure_test = test_dataset.iloc[:, 19:20]\n",
    "uv_index_test = test_dataset.iloc[:, 24:25] \n",
    "\n",
    "X_train = pd.concat([temperature_train, feels_like_train, dew_point_train, humidity_train, pressure_train, uv_index_train], axis=1)\n",
    "X_train.replace(([np.inf, -np.inf], np.nan), inplace=True)                                                            #replace any infinite values with nan\n",
    "X_train = X_train.to_numpy().astype('float64')  \n",
    "\n",
    "y_train = train_dataset.iloc[:, 30:31].to_numpy().astype('int32')\n",
    "y_true = test_dataset.iloc[:, 30:31].to_numpy().astype('int32')\n",
    "\n",
    "#https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\n",
    "test_data = pd.concat([temperature_test, feels_like_test, dew_point_test, humidity_test, pressure_test, uv_index_test], axis=1)       \n",
    "test_data.replace(([np.inf, -np.inf], np.nan), inplace=True)                                                           #replace any infinite values with nan\n",
    "X_test = test_data.to_numpy().astype('float64')  \n",
    "\n",
    "#change all nan values in all datasets with the most frequent value of the dataset\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imp.fit(X_train)\n",
    "imp.fit(y_train)\n",
    "imp.fit(X_test)\n",
    "imp.fit(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d45338ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Bayesian Optimisation!\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "Fitting 30 folds for each of 1 candidates, totalling 30 fits\n",
      "0.6949031223003828\n",
      "OrderedDict([('bootstrap', True), ('max_depth', 160), ('max_features', 'auto'), ('min_samples_leaf', 4), ('min_samples_split', 6), ('n_estimators', 1290)])\n"
     ]
    }
   ],
   "source": [
    "#https://machinelearningmastery.com/scikit-optimize-for-hyperparameter-tuning-in-machine-learning/\n",
    "def main():\n",
    "    #define search space\n",
    "    n_est = list()\n",
    "    for i in range(10, 2000, 10):\n",
    "        n_est.append(i)\n",
    "\n",
    "    params = {'n_estimators': (n_est),\n",
    "               'min_samples_split': (2,4,6,8,10,12,14,16,18,20),\n",
    "               'min_samples_leaf': (2,4,6,8,10,12,14,16,18,20),\n",
    "               'max_features': ('auto', 'sqrt', 'log2'),\n",
    "               'max_depth': (n_est[0:20]), \n",
    "               'bootstrap': (True, False)}\n",
    "    \n",
    "    # define evaluation\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    \n",
    "    # define the search\n",
    "    search = BayesSearchCV(estimator=RandomForestClassifier(), search_spaces=params, n_jobs=-1, cv=cv, verbose = 10)\n",
    "    \n",
    "    # perform the search\n",
    "    print(\"Running Bayesian Optimisation!\")\n",
    "    search.fit(X_train, y_train.ravel())\n",
    "    \n",
    "    # report the best result\n",
    "    print(search.best_score_)\n",
    "    print(search.best_params_)\n",
    "    \n",
    "if __name__ == \"__main__\":   \n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
